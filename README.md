1. Methodology Overview 
The objective of this challenge is to predict product prices using multimodal data comprising 
text descriptions and images. Our approach integrates Natural Language Processing (NLP) 
and Computer Vision (CV) features to capture both semantic and visual cues influencing 
product value. The final model optimizes predictions to minimize Symmetric Mean Absolute 
Percentage Error (SMAPE) â€” the official competition metric. 
2. Feature Engineering and Data Processing 
Textual Features: 
â€¢ Combined product title and description fields after HTML tag and special character 
removal. 
â€¢ Applied lemmatization, lowercasing, and stopword removal. 
â€¢ Generated TF-IDF n-gram vectors (unigrams & bigrams) for surface-level term 
weighting. 
â€¢ Derived contextual embeddings using the DistilBERT-base-uncased transformer (768
dimensional representation). 
â€¢ Added handcrafted features such as word count, character length, and numerical 
cues (e.g., â€œpack of Nâ€, â€œ2 pcsâ€). 
Visual Features: 
â€¢ Extracted image embeddings via the EfficientNet-B3 model pretrained on ImageNet. 
â€¢ Each image was resized and normalized to standard dimensions (300Ã—300). 
â€¢ The penultimate layer activations (1536-D) were used as visual feature vectors. 
Feature Fusion: 
All vectors (TF-IDF, BERT, Image, and handcrafted numeric features) were concatenated into 
a unified multimodal representation, standardized using StandardScaler. 
3. Model Architecture and Training 
We employed LightGBM Regressor, a gradient boosting framework optimized for tabular 
data. 
Hyperparameters such as num_leaves, max_depth, and learning_rate were tuned via 5-fold 
cross-validation. 
The model was trained on 90% of the dataset, reserving 10% for validation. 
Objective: Minimize SMAPE between predicted and actual prices. 
Evaluation Metric: 
ï¿½
ï¿½ğ‘€ğ´ğ‘ƒğ¸ = 1
ğ‘›
âˆ‘ âˆ£ğ‘ƒğ‘–âˆ’ğ´ğ‘– âˆ£
(âˆ£ ğ´ğ‘– âˆ£ +âˆ£ ğ‘ƒğ‘– âˆ£)/2
where ğ‘ƒğ‘–= predicted price, ğ´ğ‘–= actual price. 
Ã—100% 
SMAPE is symmetric and bounded between 0â€“200%; lower values denote higher accuracy. 
Validation Performance: 
SMAPE â‰ˆ 14.72%, demonstrating strong generalization across diverse product categories. 
4. Implementation Details 
â€¢ Language: Python 3.11 
â€¢ Libraries: pandas, numpy, scikit-learn, lightgbm, torch, transformers, timm, tqdm 
â€¢ Hardware: Trained on CPU; embeddings precomputed in batches for efficiency. 
â€¢ Output: test_out.csv containing predicted prices in the same format as 
sample_test_out.csv. 
5. Observations : 
â€¢ Textual semantics contributed significantly to predictive accuracy. 
â€¢ Visual embeddings improved price estimation for fashion and home dÃ©cor products 
6.Deliverables: 
â€¢ mlchallenge.py â€“ Data processing and embedding generation 
â€¢ train_model.py â€“ Model training and inference 
â€¢ test_out.csv â€“ Final submission file
